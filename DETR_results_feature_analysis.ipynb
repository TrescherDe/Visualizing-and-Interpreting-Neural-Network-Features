{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the high attention features of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"DETR_results_comparison_paper\"\n",
    "model_name1 = \"real_500_deterministic1\"\n",
    "model_name2 = \"real_500_deterministic2\"\n",
    "model_name3 = \"real_500_deterministic3\"\n",
    "model_name4 = \"storage_box_labeled_deterministic1\"\n",
    "model_name5 = \"storage_box_labeled_deterministic2\"\n",
    "model_name6 = \"storage_box_labeled_deterministic3\"\n",
    "model_name7 = \"SD_V1_deterministic1\"\n",
    "model_name8 = \"SD_V1_deterministic2\"\n",
    "model_name9 = \"SD_V1_deterministic3\"\n",
    "model_name10 = \"SD_V2_deterministic1\"\n",
    "model_name11 = \"SD_V2_deterministic2\"\n",
    "model_name12 = \"SD_V2_deterministic3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching filenames: 160\n",
      "Matching filenames: ['frame000046_rgb.pngbbox0', 'frame000050_rgb.pngbbox0', 'frame000051_rgb.pngbbox0', 'frame000053_rgb.pngbbox0', 'frame000110_rgb.pngbbox0', 'frame000114_rgb.pngbbox0', 'frame000115_rgb.pngbbox0', 'frame000117_rgb.pngbbox0', 'frame000120_rgb.pngbbox0', 'frame000123_rgb.pngbbox0', 'frame000125_rgb.pngbbox1', 'frame000126_rgb.pngbbox0', 'frame000127_rgb.pngbbox1', 'frame000128_rgb.pngbbox0', 'frame000129_rgb.pngbbox1', 'frame000130_rgb.pngbbox0', 'frame000131_rgb.pngbbox1', 'frame000132_rgb.pngbbox0', 'frame000135_rgb.pngbbox0', 'frame000136_rgb.pngbbox1', 'frame000137_rgb.pngbbox0', 'frame000138_rgb.pngbbox1', 'frame000139_rgb.pngbbox1', 'frame000140_rgb.pngbbox1', 'frame000141_rgb.pngbbox1', 'frame000142_rgb.pngbbox1', 'frame000143_rgb.pngbbox1', 'frame000144_rgb.pngbbox1', 'frame000145_rgb.pngbbox0', 'frame000146_rgb.pngbbox1', 'frame000147_rgb.pngbbox1', 'frame000148_rgb.pngbbox1', 'frame000149_rgb.pngbbox1', 'frame000150_rgb.pngbbox1', 'frame000151_rgb.pngbbox1', 'frame000152_rgb.pngbbox1', 'frame000153_rgb.pngbbox1', 'frame000154_rgb.pngbbox1', 'frame000176_rgb.pngbbox0', 'frame000177_rgb.pngbbox1', 'frame000180_rgb.pngbbox1', 'frame000181_rgb.pngbbox0', 'frame000182_rgb.pngbbox0', 'frame000182_rgb.pngbbox1', 'frame000213_rgb.pngbbox0', 'frame000214_rgb.pngbbox0', 'frame000215_rgb.pngbbox0', 'frame000216_rgb.pngbbox0', 'frame000217_rgb.pngbbox0', 'frame000218_rgb.pngbbox0', 'frame000219_rgb.pngbbox0', 'frame000220_rgb.pngbbox0', 'frame000221_rgb.pngbbox0', 'frame000222_rgb.pngbbox0', 'frame000224_rgb.pngbbox0', 'frame000225_rgb.pngbbox0', 'frame000237_rgb.pngbbox0', 'frame000238_rgb.pngbbox0', 'frame000239_rgb.pngbbox0', 'frame000240_rgb.pngbbox0', 'frame000241_rgb.pngbbox0', 'frame000242_rgb.pngbbox0', 'frame000255_rgb.pngbbox0', 'frame000256_rgb.pngbbox0', 'frame000257_rgb.pngbbox0', 'frame000258_rgb.pngbbox0', 'frame000259_rgb.pngbbox0', 'frame000260_rgb.pngbbox0', 'frame000261_rgb.pngbbox0', 'frame000262_rgb.pngbbox0', 'frame000263_rgb.pngbbox0', 'frame000264_rgb.pngbbox0', 'frame000265_rgb.pngbbox0', 'frame000266_rgb.pngbbox0', 'frame000267_rgb.pngbbox0', 'frame000268_rgb.pngbbox0', 'frame000269_rgb.pngbbox0', 'frame000270_rgb.pngbbox0', 'frame000271_rgb.pngbbox0', 'frame000272_rgb.pngbbox0', 'frame000322_rgb.pngbbox0', 'frame000323_rgb.pngbbox0', 'frame000324_rgb.pngbbox0', 'frame000325_rgb.pngbbox0', 'frame000326_rgb.pngbbox0', 'frame000327_rgb.pngbbox0', 'frame000328_rgb.pngbbox0', 'frame000329_rgb.pngbbox0', 'frame000330_rgb.pngbbox0', 'frame000331_rgb.pngbbox0', 'frame000335_rgb.pngbbox0', 'frame000336_rgb.pngbbox0', 'frame000337_rgb.pngbbox0', 'frame000342_rgb.pngbbox0', 'frame000343_rgb.pngbbox0', 'frame000344_rgb.pngbbox0', 'frame000345_rgb.pngbbox0', 'frame000346_rgb.pngbbox0', 'frame000347_rgb.pngbbox0', 'frame000348_rgb.pngbbox0', 'frame000349_rgb.pngbbox0', 'frame000353_rgb.pngbbox0', 'frame000354_rgb.pngbbox0', 'frame000355_rgb.pngbbox0', 'frame000431_rgb.pngbbox0', 'frame000432_rgb.pngbbox0', 'frame000433_rgb.pngbbox0', 'frame000434_rgb.pngbbox0', 'frame000435_rgb.pngbbox0', 'frame000436_rgb.pngbbox0', 'frame000437_rgb.pngbbox0', 'frame000438_rgb.pngbbox0', 'frame000439_rgb.pngbbox0', 'frame000440_rgb.pngbbox0', 'frame000450_rgb.pngbbox0', 'frame000451_rgb.pngbbox0', 'frame000452_rgb.pngbbox0', 'frame000453_rgb.pngbbox0', 'frame000454_rgb.pngbbox0', 'frame000455_rgb.pngbbox0', 'frame000456_rgb.pngbbox0', 'frame000459_rgb.pngbbox0', 'frame000460_rgb.pngbbox0', 'frame000461_rgb.pngbbox0', 'frame000462_rgb.pngbbox0', 'frame000464_rgb.pngbbox0', 'frame000465_rgb.pngbbox0', 'frame000466_rgb.pngbbox0', 'frame000467_rgb.pngbbox0', 'frame000485_rgb.pngbbox0', 'frame000486_rgb.pngbbox0', 'frame000487_rgb.pngbbox0', 'frame000488_rgb.pngbbox0', 'frame000489_rgb.pngbbox0', 'frame000490_rgb.pngbbox0', 'frame000491_rgb.pngbbox0', 'frame000492_rgb.pngbbox0', 'frame000493_rgb.pngbbox0', 'frame000494_rgb.pngbbox0', 'frame000495_rgb.pngbbox0', 'frame000496_rgb.pngbbox0', 'frame000497_rgb.pngbbox0', 'frame000498_rgb.pngbbox0', 'frame000499_rgb.pngbbox0', 'frame000500_rgb.pngbbox0', 'frame000501_rgb.pngbbox0', 'frame000507_rgb.pngbbox0', 'frame000508_rgb.pngbbox0', 'frame000509_rgb.pngbbox0', 'frame000510_rgb.pngbbox0', 'frame000511_rgb.pngbbox0', 'frame000512_rgb.pngbbox0', 'frame000513_rgb.pngbbox0', 'frame000514_rgb.pngbbox0', 'frame000515_rgb.pngbbox0', 'frame000516_rgb.pngbbox0', 'frame000517_rgb.pngbbox0', 'frame000518_rgb.pngbbox0', 'frame000519_rgb.pngbbox0', 'frame000520_rgb.pngbbox0']\n",
      "Average values based on the common filenames:\n",
      "Modell 1:\n",
      "Average high attention value: 0.36\n",
      "Average number of quadrants: 3.39\n",
      "Average number of big features: 1.14\n",
      "Average number of small features: 0.59\n",
      "\n",
      "Modell 2:\n",
      "Average high attention value: 0.29\n",
      "Average number of quadrants: 3.12\n",
      "Average number of big features: 1.11\n",
      "Average number of small features: 0.49\n",
      "\n",
      "Modell 3:\n",
      "Average high attention value: 0.41\n",
      "Average number of quadrants: 3.40\n",
      "Average number of big features: 1.06\n",
      "Average number of small features: 0.42\n",
      "\n",
      "Modell 4:\n",
      "Average high attention value: 0.42\n",
      "Average number of quadrants: 3.92\n",
      "Average number of big features: 1.16\n",
      "Average number of small features: 0.51\n",
      "\n",
      "Modell 5:\n",
      "Average high attention value: 0.49\n",
      "Average number of quadrants: 3.91\n",
      "Average number of big features: 1.00\n",
      "Average number of small features: 0.38\n",
      "\n",
      "Modell 6:\n",
      "Average high attention value: 0.37\n",
      "Average number of quadrants: 3.85\n",
      "Average number of big features: 1.06\n",
      "Average number of small features: 0.52\n",
      "\n",
      "Modell 7:\n",
      "Average high attention value: 0.23\n",
      "Average number of quadrants: 3.56\n",
      "Average number of big features: 0.91\n",
      "Average number of small features: 1.11\n",
      "\n",
      "Modell 8:\n",
      "Average high attention value: 0.40\n",
      "Average number of quadrants: 3.86\n",
      "Average number of big features: 1.16\n",
      "Average number of small features: 0.61\n",
      "\n",
      "Modell 9:\n",
      "Average high attention value: 0.39\n",
      "Average number of quadrants: 3.85\n",
      "Average number of big features: 1.05\n",
      "Average number of small features: 0.54\n",
      "\n",
      "Modell 10:\n",
      "Average high attention value: 0.39\n",
      "Average number of quadrants: 3.76\n",
      "Average number of big features: 1.07\n",
      "Average number of small features: 0.49\n",
      "\n",
      "Modell 11:\n",
      "Average high attention value: 0.51\n",
      "Average number of quadrants: 3.92\n",
      "Average number of big features: 1.07\n",
      "Average number of small features: 0.28\n",
      "\n",
      "Modell 12:\n",
      "Average high attention value: 0.52\n",
      "Average number of quadrants: 3.95\n",
      "Average number of big features: 1.08\n",
      "Average number of small features: 0.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def read_data(*file_paths):\n",
    "    data_files = []\n",
    "    models_data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        model_data = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.split('\\t')\n",
    "                filename = parts[0].split(\": \")[1]\n",
    "                combination_sequence = parts[1].split(\": \")[1].split()\n",
    "                high_attention = float(parts[2].split(\": \")[1].strip())\n",
    "                quadrants = ast.literal_eval(parts[3].split(\": \")[1].strip())\n",
    "                model_data[filename] = (high_attention, quadrants, combination_sequence)\n",
    "        data_files.append(model_data)\n",
    "\n",
    "    common_filenames = set(data_files[0].keys())\n",
    "    for model_data in data_files[1:]:\n",
    "        common_filenames.intersection_update(model_data.keys())\n",
    "\n",
    "    print(\"Number of matching filenames:\", len(common_filenames))\n",
    "    print(\"Matching filenames:\", sorted(common_filenames))\n",
    "\n",
    "    for filename in common_filenames:\n",
    "        file_data = [model[filename] for model in data_files]\n",
    "        models_data.append((filename, file_data))\n",
    "\n",
    "    return models_data, common_filenames\n",
    "\n",
    "\n",
    "\n",
    "def compare_models(models_data, common_filenames):\n",
    "    results = {\n",
    "        'high_attentions': [[] for _ in models_data[0][1]],\n",
    "        'quadrant_counts': [[] for _ in models_data[0][1]],\n",
    "        'big_features': [[] for _ in models_data[0][1]],\n",
    "        'small_features': [[] for _ in models_data[0][1]]\n",
    "    }\n",
    "\n",
    "    for filename, file_data in models_data:\n",
    "        if filename not in common_filenames:\n",
    "            continue\n",
    "        \n",
    "        high_attentions = [data[0] for data in file_data]\n",
    "        quadrants = [data[1] for data in file_data]\n",
    "        sequences = [data[2] for data in file_data]\n",
    "\n",
    "        for i in range(len(high_attentions)):\n",
    "            results['high_attentions'][i].append(high_attentions[i])\n",
    "            results['quadrant_counts'][i].append(len(quadrants[i]))\n",
    "            count_big = sum(1 for x in sequences[i] if x.startswith('big'))\n",
    "            count_small = sum(1 for x in sequences[i] if x.startswith('small'))\n",
    "            results['big_features'][i].append(count_big)\n",
    "            results['small_features'][i].append(count_small)\n",
    "\n",
    "    print(\"Average values based on the common filenames:\")\n",
    "    for i in range(len(results['high_attentions'])):\n",
    "        avg_high_attention = np.mean(results['high_attentions'][i])\n",
    "        avg_quadrant_count = np.mean(results['quadrant_counts'][i])\n",
    "        avg_big_features = np.mean(results['big_features'][i])\n",
    "        avg_small_features = np.mean(results['small_features'][i])\n",
    "\n",
    "        print(f\"Modell {i+1}:\")\n",
    "        print(f\"Average high attention value: {avg_high_attention:.2f}\")\n",
    "        print(f\"Average number of quadrants: {avg_quadrant_count:.2f}\")\n",
    "        print(f\"Average number of big features: {avg_big_features:.2f}\")\n",
    "        print(f\"Average number of small features: {avg_small_features:.2f}\")\n",
    "        print(\"\")\n",
    "\n",
    "filepaths = [\n",
    "    f'{folder_name}/results_comparison_{model_name1}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name2}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name3}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name4}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name5}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name6}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name7}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name8}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name9}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name10}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name11}_without_occlusion.txt',\n",
    "    f'{folder_name}/results_comparison_{model_name12}_without_occlusion.txt'\n",
    "]\n",
    "data, common_filenames = read_data(*filepaths)\n",
    "compare_models(data, common_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr_vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
